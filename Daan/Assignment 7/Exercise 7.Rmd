---
title: "Exercise 7"
author: "Daan de Jong"
date: "1/21/2021"
output: 
  ioslides_presentation:
    logo: markup_sticker_SMALL.png
    smaller: true
bibliography: refs_report.bib
---

# A presentation of random statistics and math stuff

## The model used in my thesis project {.flexbox .vcenter}

<center> <img src="model2.png" width = 50%> </center>

## The famous Iris data set

```{r, echo=FALSE, warning=FALSE}
library(DT)
datatable(iris, options = list(pageLength = 5))
```

## Differential Calculus 

The function $x \mapsto \frac{1}{16}x^4$ and its first 4 derivatives

```{r, echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE}
library(plotly)
library(ggplot2)

x <- seq(from=-10, to=10, by=.05)
range <- length(x)

data <- data.frame(x = rep(x, times=5), 
                   y = round(c(.0625*(x**4),
                         .25*(x**3),
                         .75*(x**2),
                         1.5*x,
                         rep(1.5, times=range)), 2),
                   group = c(rep('zeroth derivative', times=range),
                             rep('first derivative', times=range),
                             rep('second derivative', times=range),
                             rep('third derivative', times=range),
                             rep('fourth derivative', times=range))
)

plot <- ggplot(aes(x=x, y=y, color=group), data=data) +
  geom_line() +
  ylim(-100,100)

ggplotly(plot)
```

## A random piece from my Thesis Report

<div class="columns-2">
The data set consists of 14462 sentences with their negation cue and negation scope annotations. After standardization and tokenization, a sentence $s_i$ is represented by a vector $\mathbf{x}_i = (x_{1_i}~\cdots~x_{t_i}~\cdots~x_{n_i})^{\prime}$ of tokens, where $i$ is the sentence index, $n_i$ is the number of tokens in the sentence and $t = 1,2, \dots, n$ is its token index. In the current study, hyphenated words were considered as one token, and commas and periods were excluded. This resulted in 17602 unique tokens. Let the vocabulary $X = \{x_1,\dots, x_{17602}\}$ be the ordered set of tokens and $V=\{1,\dots,|X|\}$ the set of their indices, so that every token is associated with a unique vocabulary index in V. Then, a token vector $\mathbf{x}_i$ can be vectorized by mapping each $x_{t_i}$ to its vocabulary index $v_{t_i} \in V$, obtaining a sequence $\mathbf{v}_i = (v_{1_i}~\cdots~v_{n_i})^{\prime}$ for each sentence $s_i$.

Each sentence $s_i$ is associated with a negation cue vector and a negation scope vector. The cue vector $\mathbf{c}_i = (c_{1_i}~\cdots~c_{n_i})^{\prime} \in \{0,1\}^{n_i}$ indicates which tokens are annotated as a cue token, so $c_{t_i}=1$ if the $t$-th token from the corresponding token vector $\mathbf{x}_i$ is a negation cue and $c_{t_i}=0$ otherwise. The scope vector of sentence $s_i$ is defined as $\mathbf{y}_i=(y_{1_i}~\cdots~y_{n_i})^{\prime} \in \{0,1\}^{n_i}$, where $y_{t_i}=1$ if the $t$-th token from $\mathbf{x}_i$ is annotated as a negation cue or affected by it, and $y_{t_i}=0$ otherwise. This vector is referred to as the label vector.
</div>

## Surface area of a sphere with integral calculus

$$\begin{aligned}\int_{\mathcal{S}} \mathrm{d}S &= \int_{0}^{\pi} \int_{0}^{2\pi} r^2 \sin\varphi ~\mathrm{d}\theta\mathrm{d}\varphi \\
&= r^2 \int_{0}^{\pi} \sin\varphi \left(\int_{0}^{2\pi} \mathrm{d}\theta \right) \mathrm{d}\varphi \\
&= 2\pi r^2 \int_{0}^{\pi} \sin\varphi ~\mathrm{d}\varphi \\
&= 2\pi r^2 (-\cos\varphi) \Big|_0^\pi \\
&= 4\pi r^2. \end{aligned}$$

## LSTM

A Long Short-Term Memory (LSTM) Neural Network is a type of Recurrent Neural Network that is capable of retaining information from longer input sequences [@hochreiter]

## Simulation of the Monty Hall problem

```{r, eval=FALSE}
switch <- FALSE
prices <- rep(NA,10000)

for (i in 1:10000){
  carsWon <- 0
  doors  <- sample(c("car", "goat", "goat"), size=3, replace=F)
  choice <- sample(1:3, size=1)
  
  if (doors[choice] == "car"){
    show <- sample((1:3)[-choice], size=1)
  } else if (doors[choice] == "goat"){
    car  <- which(doors == "car")
    show <- (1:3)[-c(choice, car)]
  }
  
  if (switch == TRUE) {
    price <- doors[-c(choice, show)]
  } else price <- doors[choice]
  
  prices[i] <- price
}

mean(prices == "car")
```

# References

